import os
import csv
import json
import shutil
from datasets import load_dataset, Audio
from tqdm import tqdm
import soundfile as sf
import librosa
from dotenv import load_dotenv
load_dotenv()
TARGET_SR = 44100  # Target sample rate

# ========== CONFIG ==========
HF_TOKEN = os.getenv("HF_TOKEN")
HF_DATASET = "dolly-vn/dolly-audio-1000h-vietnamese"     # v√≠ d·ª•: "librispeech_asr"
HF_SPLIT = "train"                       # train / validation / test
PARENT_DIR = "/mnt/d/tts_dataset/"                   # folder output
PARENT_DIR_BACKUP = "/mnt/c/Users/xuhet/Downloads/tts_dataset/"            # folder backup khi h·∫øt dung l∆∞·ª£ng

AUDIO_COLUMN = "audio"                   # c·ªôt audio trong HF dataset
TEXT_COLUMN = "text"                     # c·ªôt transcript
MIN_FREE_SPACE_GB = 0.3                  # Ng∆∞·ª°ng dung l∆∞·ª£ng tr·ªëng t·ªëi thi·ªÉu (GB)
# ============================


def get_free_space_gb(path):
    """Tr·∫£ v·ªÅ dung l∆∞·ª£ng tr·ªëng c·ªßa ·ªï ƒëƒ©a ch·ª©a path (t√≠nh b·∫±ng GB)."""
    total, used, free = shutil.disk_usage(path)
    return free / (1024 ** 3)


def main():
    # Bi·∫øn ƒë·ªÉ theo d√µi th∆∞ m·ª•c ƒëang d√πng
    current_parent_dir = PARENT_DIR
    switched_to_backup = False

    # T·∫°o th∆∞ m·ª•c output
    wavs_dir = os.path.join(current_parent_dir, "wavs")
    os.makedirs(wavs_dir, exist_ok=True)

    metadata_path = os.path.join(current_parent_dir, "metadata.csv")
    jsonl_path = os.path.join(current_parent_dir, "metadata.jsonl")
    
    csv_file = open(metadata_path, "w", newline="", encoding="utf-8")
    jsonl_file = open(jsonl_path, "w", encoding="utf-8")
    writer = csv.writer(csv_file, delimiter="|")

    print(f"üì• Loading dataset {HF_DATASET} (streaming)...")

    # üî• FIX QUAN TR·ªåNG: √©p audio decode sang numpy
    dataset = load_dataset(
        HF_DATASET,
        split=HF_SPLIT,
        streaming=True,
        token=HF_TOKEN
    ).cast_column(AUDIO_COLUMN, Audio(decode=True))

    print("üéß B·∫Øt ƒë·∫ßu t·∫£i v√† l∆∞u audio...")

    idx = 1
    for sample in tqdm(dataset, desc="Processing"):
        audio_obj = sample[AUDIO_COLUMN]

        # HF tr·∫£ v·ªÅ:
        # audio_obj["array"]  (numpy array)
        # audio_obj["sampling_rate"]

        array = audio_obj["array"]
        sr = audio_obj["sampling_rate"]

        # Resample to target sample rate (44.1kHz)
        if sr != TARGET_SR:
            array = librosa.resample(array, orig_sr=sr, target_sr=TARGET_SR)
            sr = TARGET_SR

        # T√™n file output
        filename = f"audio_{idx:06d}.wav"
        filepath = os.path.join(wavs_dir, filename)

        # Save b·∫±ng soundfile
        sf.write(filepath, array, sr)

        # Transcript
        text = sample[TEXT_COLUMN].replace("\n", " ").strip()

        # Calculate duration in seconds
        duration = round(len(array) / sr, 2)

        # Ghi metadata CSV
        writer.writerow([filename, text])

        # Ghi metadata JSONL
        jsonl_entry = {
            "audio": os.path.join(current_parent_dir, "wavs", filename),
            "text": text,
            "duration": duration
        }
        jsonl_file.write(json.dumps(jsonl_entry, ensure_ascii=False) + "\n")

        # Ki·ªÉm tra dung l∆∞·ª£ng ƒëƒ©a sau m·ªói iteration
        if not switched_to_backup:
            free_space = get_free_space_gb(current_parent_dir)
            if free_space < MIN_FREE_SPACE_GB:
                print(f"\n‚ö†Ô∏è ·ªî ƒëƒ©a hi·ªán t·∫°i c√≤n {free_space:.2f} GB (< {MIN_FREE_SPACE_GB} GB)")
                print(f"üîÑ Chuy·ªÉn sang th∆∞ m·ª•c backup: {PARENT_DIR_BACKUP}")
                
                # ƒê√≥ng c√°c file metadata hi·ªán t·∫°i
                csv_file.close()
                jsonl_file.close()
                
                # Chuy·ªÉn sang th∆∞ m·ª•c backup
                current_parent_dir = PARENT_DIR_BACKUP
                switched_to_backup = True
                
                # T·∫°o th∆∞ m·ª•c backup
                wavs_dir = os.path.join(current_parent_dir, "wavs")
                os.makedirs(wavs_dir, exist_ok=True)
                
                # M·ªü file metadata m·ªõi ·ªü th∆∞ m·ª•c backup (append mode)
                metadata_path = os.path.join(current_parent_dir, "metadata.csv")
                jsonl_path = os.path.join(current_parent_dir, "metadata.jsonl")
                csv_file = open(metadata_path, "a", newline="", encoding="utf-8")
                jsonl_file = open(jsonl_path, "a", encoding="utf-8")
                writer = csv.writer(csv_file, delimiter="|")
                
                print(f"‚úÖ ƒê√£ chuy·ªÉn sang {PARENT_DIR_BACKUP}, ti·∫øp t·ª•c x·ª≠ l√Ω...")

        idx += 1

    csv_file.close()
    jsonl_file.close()
    print("‚úÖ DONE! Saved to:", current_parent_dir)
    if switched_to_backup:
        print(f"üìÅ D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh 2 ·ªï ƒëƒ©a: {PARENT_DIR} v√† {PARENT_DIR_BACKUP}")


if __name__ == "__main__":
    main()